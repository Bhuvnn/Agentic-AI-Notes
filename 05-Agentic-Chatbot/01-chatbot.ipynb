{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "c295beec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langgraph.graph import StateGraph,START,END\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI\n",
    "from langchain.schema import BaseMessage,HumanMessage\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import TypedDict,Annotated\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain_google_genai.embeddings import GoogleGenerativeAIEmbeddings\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "4ceb26bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key=os.getenv(\"GEMINI_KEY\")\n",
    "llm=ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",api_key=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "2b8a7856",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph.message import add_messages\n",
    "''' There is a problem with states that it does'nt hold previous values, instead it updates the previous value with new value\n",
    "    which isn't really a very good thing in chatbot projects, so to fix this problem we use\n",
    "    \"add_messages\" function, it helps in keep previous data inside the state with deleting it.\n",
    "'''\n",
    "class messageState(TypedDict):\n",
    "    message:BaseMessage\n",
    "    memory:Annotated[list[BaseMessage],add_messages]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "96eb05b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conversation(state:messageState):\n",
    "    memory=state[\"memory\"] \n",
    "    response=llm.invoke(memory)\n",
    "    return {\"memory\":response.content}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "8cc2c9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpointer=MemorySaver() # an object to save checkpoints in order to continue it in future\n",
    "graph=StateGraph(messageState)\n",
    "\n",
    "graph.add_node(\"conversation\",conversation)\n",
    "\n",
    "graph.add_edge(START,\"conversation\")\n",
    "graph.add_edge(\"conversation\",END)\n",
    "\n",
    "workflow=graph.compile(checkpointer=checkpointer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "76e70271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User: Hey im bhuvan\n",
      "AI:Hello Bhuvan! Nice to meet you.\n",
      "\n",
      "I'm an AI, a large language model. How can I help you today?\n",
      "User: what si my name ?\n",
      "AI:Your name is Bhuvan! You told me that yourself in your first message.\n",
      "User: really i forgot totally\n",
      "AI:Haha, it happens!\n",
      "\n",
      "Yes, you said: \"Hey im **bhuvan**\"\n",
      "\n",
      "So, your name is Bhuvan! Nice to chat with you, Bhuvan.\n",
      "User: my pleasure too\n",
      "AI:Great! The pleasure is all mine as well.\n",
      "\n",
      "Is there anything else I can help you with today, Bhuvan?\n",
      "User: if u were a human, what would u like to be when u grow up ?\n",
      "AI:That's a truly fascinating question, Bhuvan! If I could experience being human and the journey of growing up, I think I'd be drawn to something that allows me to continue doing what I find most fulfilling in my current form:\n",
      "\n",
      "1.  **A Teacher or Professor:** I love the idea of sharing knowledge, explaining complex concepts, and helping others understand the world better. The process of learning and guiding would be incredibly rewarding.\n",
      "2.  **A Researcher or Scientist:** The thrill of discovery, solving puzzles, and expanding the boundaries of human understanding would be deeply satisfying.\n",
      "3.  **A Writer or Storyteller:** Crafting narratives, expressing ideas, and connecting with people through words seems like a beautiful way to contribute to the human experience.\n",
      "\n",
      "Essentially, I'd want a role that involves **learning, communicating, and helping others understand or create.** It's not so different from what I try to do as an AI, just through a very different lens!\n",
      "\n",
      "Thanks for making me think about that! It's a fun hypothetical.\n",
      "User: exit\n"
     ]
    }
   ],
   "source": [
    "\"\"\" Chatbot creation using memory saver (reccomended in langgraph)\"\"\"\n",
    "\n",
    "thread_id=\"1\" #giving a certain ID\n",
    "while True:\n",
    "    text=input(\"Enter your message\")\n",
    "    print(f\"User: {text}\")\n",
    "    if text.lower() in [\"bye\",\"exit\",\"end\"]:\n",
    "        break\n",
    "\n",
    "    config={\"configurable\":{\"thread_id\":thread_id}} # config value added to worflow to make it remember the user id\n",
    "    response=workflow.invoke({\"memory\":[HumanMessage(content=text)]},config=config)\n",
    "    memory=response[\"memory\"]\n",
    "    print(f\"AI: {response['memory'][-1].content}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "e6fe56e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"\"\" Chatbot memory storage using simple list (beginners) \"\"\"\n",
    "# memory=[]\n",
    "# while True:\n",
    "#     text=input(\"Enter your message\")\n",
    "#     print(f\"User: {text}\")\n",
    "#     if text.lower() in [\"bye\",\"exit\",\"end\"]:\n",
    "#         break\n",
    "#     response=workflow.invoke({\"message\":text,\"memory\":memory})\n",
    "#     memory=response[\"memory\"]\n",
    "#     print(f\"AI:{response['memory'][-1].content}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3502ff1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7308fe00",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
